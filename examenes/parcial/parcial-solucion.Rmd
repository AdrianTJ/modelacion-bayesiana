---
title: "Examen parcial - Primavera 2021"
author: Alfredo Garbuno Iñigo
output: html_document
---

**Entrega:** 

Enviar por correo electrónico una carpeta comprimida
(`equipo-xx.zip`) que incluya datos y codigo de solución a mas tardar el 23 de
Marzo antes de las 11:59pm (medianoche). El asunto deberá ser `[MB - 2021]
Parcial Equipo XX`, donde  reemplazarás `XX` con el codigo de tu equipo. No se
aceptarán entregas extemporáneas. Será mejor entregar un examen resuelto
parcialmente, que no entregar nada.

**Instrucciones:**
  
* Tus respuestas deben ser claras y debes explicar los resultados, incluye
también tus procedimientos/código de manera ordenada, y el código comentado.

* Se evaluará la presentación de resultados (calidad de las gráficas, tablas,
...).

* Las sesiones de dudas del Miércoles 17 de Marzo será completamente para
responder dudas del examen. Adicionalmente, en las sesiones del Martes 16 y
Jueves 18 se reservará una media hora para dudas (dependerá de la agenda cuál
será el momento mas oportuno para abrir el espacio).

* No pueden compartir soluciones entre diferentes equipos.

* Al entregar este examen afirmas que el trabajo se realizó sólo con tu
compañeros de equipo. El material que utilizaste para apoyarte consistió de las
notas en clase (pdfs en Canvas), el codigo fuente de las notas en el repositorio
de Github.

* Al entregar estás dando tu consentimiento para que bajo sospecha y suficiente
evidencia de copia se anule tu evaluación.

```{r setup, include=FALSE}

library(tidymodels)
library(tidyverse)
library(cmdstanr)
library(rstanarm)
library(bayesplot)
library(loo)

library(patchwork)
library(scales)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning=FALSE, 
                      fig.align = 'center', fig.width = 5, fig.height=3, cache = TRUE)
comma <- function(x) format(x, digits = 2, big.mark = ",")
theme_set(theme_linedraw())

SEED <- 108727

```

## Datos: !Kung San.

Los datos que que tenemos en `Howell.txt` son datos parciales del censo para el
área de Dobe, en particular para la población de los [!Kung
San.](https://es.wikipedia.org/wiki/!Kung) Éstos fueron recopilados a partir de
entrevistas realizadas por Nancy Howell a finales de la década de 1960.

a ) Los pesos presentados a continuación se registraron en el censo !Kung, pero no
se registraron las alturas para estas personas. Proporciona predicciones para
las alturas e intervalos del 89% para cada uno de estos individuos basados en un
modelo de regresión lineal.

```{r leer kung}

howell <- read_delim("howell.csv", delim = ";")
howell %>% head()

```

```{r}

m.howell.a <- stan_glm(altura ~ peso, data = howell, refresh = 0, seed = SEED)

summary(m.howell.a)

```



```{r}

howell.new <- tibble(peso = c(46.95, 43.72, 64.78, 32.59, 54.63))

posterior_predict(m.howell.a, newdata = howell.new) %>% 
  as_tibble() %>% 
  map_df(quantile, probs = c(0.055, .5, 0.945)) %>% 
  mutate(peso = howell.new$peso)

```

b) Ajusta un modelo lineal para personas menores de 18 años de edad utilizando
como predictores la `edad` y el `peso`. Interpreta los coeficientes que resultan
del modelo. Si consideras necesario centra los valores de las variable
predictoras.

```{r}

howell.menores <- howell %>% filter(edad < 18) %>% 
  mutate(edad.c = edad - mean(edad), 
         peso.c = peso - mean(peso))

m.howell.b <- stan_glm(altura ~ edad.c + peso.c, 
                       data = howell.menores, 
                       refresh = 0, 
                       seed = SEED)
summary(m.howell.b)

```

c) Para el modelo resultante, haz gráficos que muestren la relación de la
variable objetivo con los predictores. De igual forma, incorpora en la
visualización la respuesta del modelo lineal junto con intervalos de predicción
al 89\% y 97\%, de tal forma que incorpores la incertidumbre que se ha
cuantificado en tu gráfico.

```{r}

howell.menores %>% 
  ggplot(aes(edad, altura)) + 
    geom_point()

howell.prom <- howell.menores %>% 
  summarise(edad = mean(edad), 
            peso = mean(peso))

howell.prom

```

```{r}

howell.peso <- tibble(peso = seq(0, 50, length.out = 500), edad = howell.prom$edad) %>% 
  mutate(peso.c = peso - howell.prom$peso, 
         edad.c = 0)

g1 <- posterior_predict(m.howell.b, newdata = howell.peso) %>% 
  as_tibble() %>% 
  map_df(quantile, probs = c(0.015, 0.055, .5, 0.945, 0.985))  %>% 
  cbind(howell.peso) %>% 
  ggplot(aes(peso, `50%`)) + 
    geom_ribbon(aes(ymin = `5.5%`, ymax = `94.5%`), alpha = .2) +
    geom_ribbon(aes(ymin = `1.5%`, ymax = `98.5%`), alpha = .2) + 
    geom_line() + 
    geom_point(data = howell.menores, 
               aes(peso, altura)) + 
    labs(x = 'Peso', y = 'Altura', title = 'Prediccion de Altura (Peso)')

```

```{r}

howell.edad <- tibble(edad = seq(0, 17.5, length.out = 500), 
                      peso = howell.prom$peso) %>% 
  mutate(peso.c = 0, 
         edad.c = edad - howell.prom$edad)

g2 <- posterior_predict(m.howell.b, newdata = howell.edad) %>% 
  as_tibble() %>% 
  map_df(quantile, probs = c(0.015, 0.055, .5, 0.945, 0.985))  %>% 
  cbind(howell.edad) %>% 
  ggplot(aes(edad, `50%`)) + 
    geom_ribbon(aes(ymin = `5.5%`, ymax = `94.5%`), alpha = .2) +
    geom_ribbon(aes(ymin = `1.5%`, ymax = `98.5%`), alpha = .2) + 
    geom_line() + 
    geom_point(data = howell.menores, 
               aes(edad, altura)) + 
    labs(x = 'Edad', y = 'Altura', title = 'Prediccion de Altura (Edad)')

```


```{r}

g1 + g2

```

d) Supongamos que tenemos una amiga que es experta en
[alometría](https://es.wikipedia.org/wiki/Alometr%C3%ADa) y les menciona que el
peso es suficiente, pero que se debería de incorporar en términos de una escala
logarítmica. Ajusta el modelo con todos las observaciones y compara con el
modelo del inciso a) y un modelo adicional que sólo incorpora el `peso`. ¿Cuál
parece tener mejor capacidad predictiva?

```{r}

m.howell.d <- stan_glm(altura ~ log(peso), data = howell, 
                       refresh = 0, seed = SEED)

summary(m.howell.d)

```

```{r}

(loo.a <- loo(m.howell.a))
(loo.d <- loo(m.howell.d))

```

```{r}

(loo_compare(loo.a, loo.d))

```


e) ¿Cómo interpretas los coeficientes del mejor modelo del inciso `d`?

f) Ahora estudiaremos el efecto de la distribución previa. Para esto
consideraremos. La variable de `edad` centrada y probaremos distintos polinomios
como predictores. Consideraremos potencias desde 0 hasta términos de grado 6.
Ajusta esta colección de posibles modelos. 

```{r}
howell <- howell %>% 
  mutate(edad.c = edad - mean(edad))

ajusta_polinomio <- function(degree){
  if (degree == 0){
    stan_glm(altura ~ 1, 
             data = howell, 
             refresh = 0, 
             seed = SEED)
  } else {
    stan_glm(altura ~ poly(edad.c, degree, raw = FALSE), 
             data = howell, 
             refresh = 0, 
             seed = SEED)
  }
}

modelos <- tibble(degree = seq(0, 6)) %>% 
  mutate(modelo = map(degree, ajusta_polinomio))

```

```{r}

modelos %>% pull(modelo) %>% map(summary)

```


>> ¡ Medio punto extra ! 

g) Para cada modelo en el inciso de arriba, genera graficos que muestren las
predicciones junto con las bandas de predicción. 

```{r}

# howell %>% 
#   ggplot(aes(edad, altura)) + 
#     geom_point()

calcula_predicciones <- function(modelo){
  
  newdata <- tibble(edad = seq(0, 85, length.out = 100)) %>% 
    mutate(edad.c = edad - mean(howell$edad))
  
  posterior_predict(modelo, newdata = newdata) %>%
    as_tibble() %>%
    map_df(quantile, probs = c(0.015, 0.055, .5, 0.945, 0.985)) %>%
    mutate(edad = newdata$edad)
  
}

modelos <- modelos %>% 
  mutate(predicciones = map(modelo, calcula_predicciones))

```

```{r}

modelos %>% 
  unnest(predicciones) %>% 
  ggplot(aes(edad, `50%`)) + 
    geom_ribbon(aes(ymin = `5.5%`, ymax = `94.5%`), alpha = .2) +
    geom_ribbon(aes(ymin = `1.5%`, ymax = `98.5%`), alpha = .2) + 
    geom_line() + 
    geom_point(data = howell, 
               aes(edad, altura), 
               size = .2) + 
    facet_wrap(~degree) + 
    labs(x = 'Edad', y = 'Altura', title = 'Regresión polinomial (Edad)')

```

h) Realiza una evaluación de los modelos resultantes con el criterio de
información que consideres más apropiado.

```{r}

modelos <- modelos %>% 
  mutate(criteria = map(modelo, loo))

modelos %>% 
  select(criteria) %>% 
  pull(criteria)

criteria.list <- (modelos %>% pull(criteria))
names(criteria.list) <- paste("degree", modelos$degree, sep = '')

```

```{r}
loo_compare(criteria.list)
```

i) Ahora ajustaremos un polinomio de grado 6 pero incorporaremos distribuciones
previas mas restrictivas. Es decir, considera que $\beta_k \sim \mathsf{N}(0,
\sqrt{5})$ para toda $k.$ Nota que la desviación estandar es $\sqrt{5}.$ Evalúa
el criterio de información que utlizaste en el inciso anterior, y compara la
estimación de número efectivo de parámetros. ¿Por qué crees que sucede esto?

```{r}

m.howell.i <- stan_glm(altura ~ poly(edad.c, 6, raw = FALSE), 
       data = howell, 
       prior = normal(0, sqrt(5)),
       refresh = 0, 
       seed = SEED)

summary(m.howell.i)

```

```{r}

(loo.i <- loo(m.howell.i))

```

```{r}

loo_compare(criteria.list[[5]], loo.i)

```

```{r}

calcula_predicciones(m.howell.i) %>% 
  ggplot(aes(edad, `50%`)) + 
    geom_ribbon(aes(ymin = `5.5%`, ymax = `94.5%`), alpha = .2) +
    geom_ribbon(aes(ymin = `1.5%`, ymax = `98.5%`), alpha = .2) + 
    geom_line() + 
    geom_point(data = howell, 
               aes(edad, altura), 
               size = .2) + 
    labs(x = 'Edad', y = 'Altura', 
         title = 'Regresión polinomial regularizada (Edad)')

```


## Datos: Vinos.

Consideremos el conjunto de datos en `vinos.txt`. Estos datos son evaluaciones
de 20 vinos diferentes, tanto franceses y estadounidenses, realizadas por 9
jueces (también, franceses y estadounidenses) diferentes. El objetivo de este
ejercicio es modelar el `score`, la calificación subjetiva que cada juez asigna
a cada vino. Recomiendo centrarlo para el ajuste de los modelos.

```{r}

vinos <- read_delim("vinos.txt", delim = ";")
vinos <- vinos %>% 
  mutate(score.c = score - mean(score))

```


a) En este inciso, sólo considera la variación entre jueces y
vinos. Ajusta un modelo de regresión lineal utilizando estos predictores.
Justifica tu distribución _a priori_. ¿Cómo interpretas la variación entre
jueces individuales y vinos individuales? ¿Notas algún patrón (puedes utilizar
`mcmc_areas`)? ¿Qué jueces dieron las calificaciones más altas / más bajas? ¿Qué
vinos fueron calificados como peores / mejores en promedio?

```{r}
m.vinos.a <- stan_glm(score.c ~ -1 + judge + wine, 
                 data = vinos, 
                 refresh = 0, 
                 seed = SEED)

summary(m.vinos.a)
```


```{r}

mcmc_areas(as.matrix(m.vinos.a), regex_pars = c("judge"))
mcmc_areas(as.matrix(m.vinos.a), regex_pars = c("wine"))

```

b) Ajusta con la previa _default_ en `stan_glm`. Después, ajusta de nuevo el
modelo con una distribución a priori regularizada (incorpora `prior = hs()` en
las opciones). ¿Que observas al comparar la $R^2$-Bayesiana de ambos modelos?
¿Cómo explicas éste comportamiento? Por otro lado, calcula la capacidad
predictiva por medio de `loo` o `waic` (el que tu elijas) en ambos y describe lo
que observas en el estadistico que describe el número efectivo de parámetros.
¿Cómo justificas este comportamiento? ¿Cómo concilias lo observado en la $R^2_B$
y la comparación de devianza entre ambas posibilidades?

```{r}
m.vinos.b <- stan_glm(score.c ~ wine + judge, 
                 data = vinos,
                 prior = hs(),
                 refresh = 0, 
                 seed = SEED)

summary(m.vinos.b)
```


```{r}
gb <- ggplot() + 
    geom_histogram(aes(x = bayes_R2(m.vinos.b))) + xlim(0,1)

ga <- ggplot() + 
    geom_histogram(aes(x = bayes_R2(m.vinos.a))) + xlim(0,1)

ga / gb

```

```{r}

(loo.a <- loo(m.vinos.a))
(loo.b <- loo(m.vinos.b))

loo_compare(loo.a, loo.b)

# ggplot() + 
#     geom_histogram(aes(x = bayes_R2(m.vinos.a)), fill = 'red', alpha = .2) + 
#     geom_histogram(aes(x = bayes_R2(m.vinos.b)), alpha = .2, fill = 'blue') + 
#     xlim(0,1)

```
```{r}

mcmc_areas(as.matrix(m.vinos.b), regex_pars = c("judge"))
mcmc_areas(as.matrix(m.vinos.b), regex_pars = c("wine"))

```


c) Ahora considera como predictores `flight`(el tipo de vino), `wine.amer` (de
dónde proviene), y `judge.amer` (indicador si el juez es americano). Para este
inciso no incluyas las variables de los casos anteriores. De igual manera,
justifica la selección de distribución previa que utilizas. ¿Cómo se relacionan
estas estimaciones con lo que observaste en el inciso `a`?

```{r}

m.vinos.c <- stan_glm(score.c ~ flight + wine.amer + judge.amer, 
                 data = vinos,
                 refresh = 0, 
                 seed = SEED)

summary(m.vinos.c)

```
```{r}

(loo.c <- loo(m.vinos.c))

```

```{r}
loo_compare(loo.a, loo.b, loo.c)
```


d) Ahora considera todas las posibles interacciones de dos términos con las tres
variables de arriba. Explica lo que significa cada término e interpreta los
coeficientes. ¿Cómo se relacionan estos resultados con los del inciso `a` de
esta sección?

```{r}

m.vinos.c <- stan_glm(score.c ~ flight + wine.amer + judge.amer + 
                        flight:wine.amer +  wine.amer:judge.amer + flight:judge.amer, 
                 data = vinos,
                 refresh = 0, 
                 seed = SEED)

summary(m.vinos.c)

```


## Datos: Nettle 

Utiliza los datos en `nettle.txt` para evaluar la hipótesis de que la diversidad
lingüística es producto de la seguridad alimentaria. Los datos contienen mediciones para: 

1) `pais`: Nombre del país.
2) `num.leng`: Número de lenguajes identificados en dicho país.
3) `area`: Area medida en kilómetros cuadrados.
4) `k.pob`: Población en miles. 
5) `num.stations`: Número de estaciones que proveen las siguientes. 
6) `mean.growing.season`: Duración promedio de la temporada de cosecha, medida
en meses. 
7) `sd.growing.season`: Desviación estándar de la duración de la
temporada de cosecha, medidad en meses.

La idea es que, en las ecologías productivas, las personas no necesitan grandes
redes sociales para protegerse contra el riesgo de escasez de alimentos. Esto
significa que los grupos culturales pueden ser más pequeños y más
autosuficientes, lo que lleva a más idiomas per cápita. Utiliza el número de
idiomas per cápita como resultado:

```{r, eval = FALSE}

data %>% 
    mutate(leng.per.cap = num.leng/k.pob)

```

Utilice el logaritmo de esta nueva variable como el objetivo de un modelo de
regresión. Este problema tiene un final abierto, lo que les permite decidir cómo
abordar las hipótesis y las predicciones inciertas que proporciona el modelo. Si
creen que necesita usar WAIC/LOO en cualquier momento, hágamlo. Si creen que necesitan
cierta distribución previa, argumenten por ella. Si creen que necesitan mostrar
las predicciones de cierta manera, háganlo. Traten de evaluar honestamente
los efectos principales de la temporada media de crecimiento
(`mean.growing.season`) y la desviación de la temporada de crecimiento
(`sd.growing.season`), así como su interacción.

a) Evalúe la hipótesis de que la diversidad lingüística, medida por
`log(lang.per.cap)`, está asociada positivamente con la duración promedio de la
temporada de crecimiento, `mean.growing.season`. Considera tambíen  `log(area)`
en tu modelo (no como una interacción). Interpreten sus resultados.

b) Ahora evalúen la hipótesis de que la diversidad lingüística está asociada
negativamente con la desviación estándar de la duración de la temporada de
crecimiento. Esta hipótesis se deriva de la incertidumbre en la cosecha que
favorece la seguridad social a través de redes sociales más amplias y, por lo
tanto, menos idiomas. Nuevamente, considere `log(area)` como una covariable (no
una interacción). Interpreten sus resultados.

c) Finalmente, evalúen la hipótesis de que `mean.growing.season` y
`sd.growing.season` interactúan para reducir sinérgicamente la diversidad del
lenguaje. La idea es que, en naciones con temporadas de cultivo en promedio más
largas, la alta variación hace que el almacenamiento y la redistribución sean
aún más importantes de lo que serían de otra manera. De esa manera, las personas
pueden cooperar para preservar y proteger las ganancias inesperadas que se
utilizarán durante las sequías.