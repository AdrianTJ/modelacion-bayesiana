@book{Gelman2020,
  author       = {Gelman, Andrew and Hill, Jennifer and Vehtari, Aki},
  title        = {Regression and Other Stories},
  year         = 2020,
  publisher    = {Cambridge University Press},
}

@book{Mcelreath2020,
  author       = {McElreath, Richard},
  title        = {Statistical Rethinking: A Bayesian course with
                  examples in R and Stan},
  year         = 2020,
  publisher    = {CRC Press},
}

@book{Gelman2013,
  author       = {Gelman, Andrew and Carlin, John B and Stern, Hal S
                  and Dunson, David B and Vehtari, Aki and Rubin,
                  Donald B},
  title        = {Bayesian Data Analysis},
  year         = 2013,
  publisher    = {CRC Press},
}

@article{Vehtari2021,
  author       = {Vehtari, Aki and Simpson, Daniel and Gelman, Andrew
                  and Yao, Yuling and Gabry, Jonah},
  title        = {Pareto {{Smoothed Importance Sampling}}},
  journal      = {arXiv:1507.02646},
  year         = 2021,
  abstract     = {Importance weighting is a general way to adjust
                  Monte Carlo integration to account for draws from
                  the wrong distribution, but the resulting estimate
                  can be noisy when the importance ratios have a heavy
                  right tail. This routinely occurs when there are
                  aspects of the target distribution that are not well
                  captured by the approximating distribution, in which
                  case more stable estimates can be obtained by
                  modifying extreme importance ratios. We present a
                  new method for stabilizing importance weights using
                  a generalized Pareto distribution fit to the upper
                  tail of the distribution of the simulated importance
                  ratios. The method, which empirically performs
                  better than existing methods for stabilizing
                  importance sampling estimates, includes stabilized
                  effective sample size estimates, Monte Carlo error
                  estimates and convergence diagnostics.},
  archiveprefix= {arXiv},
  eprint       = {1507.02646},
  eprinttype   = {arxiv},
  file         = {/Volumes/GoogleDrive/My Drive/bibliography/Journal
                  Article/Vehtari2021 - Pareto Smoothed Importance
                  Sampling.pdf;/Volumes/GoogleDrive/My
                  Drive/bibliography/Journal Article/Vehtari2021 -
                  Pareto Smoothed Importance Sampling2.pdf},
  keywords     = {Statistics - Computation,Statistics - Machine
                  Learning,Statistics - Methodology},
  langid       = {english},
  month        = {feb},
  primaryclass = {stat},
}

@article{Gabry2019,
  author       = {Gabry, Jonah and Simpson, Daniel and Vehtari, Aki
                  and Betancourt, Michael and Gelman, Andrew},
  title        = {Visualization in {{Bayesian}} Workflow},
  journal      = {Journal of the Royal Statistical Society: Series A
                  (Statistics in Society)},
  volume       = 182,
  number       = 2,
  pages        = {389--402},
  year         = 2019,
  doi          = {10.1111/rssa.12378},
  abstract     = {Bayesian data analysis is about more than just
                  computing a posterior distribution, and Bayesian
                  visualization is about more than trace plots of
                  Markov chains. Practical Bayesian data analysis,
                  like all data analysis, is an iterative process of
                  model building, inference, model checking and
                  evaluation, and model expansion. Visualization is
                  helpful in each of these stages of the Bayesian
                  workflow and it is indispensable when drawing
                  inferences from the types of modern, high
                  dimensional models that are used by applied
                  researchers.},
  file         = {/Volumes/GoogleDrive/My Drive/bibliography/Journal
                  Article/Gabry2019 - Visualization in Bayesian
                  workflow.pdf},
  issn         = {0964-1998, 1467-985X},
  langid       = {english},
  month        = {feb},
}

@article{Betancourt2018,
  author       = {Betancourt, Michael},
  title        = {Calibrating {{Model}}-{{Based Inferences}} and
                  {{Decisions}}},
  journal      = {arXiv:1803.08393},
  year         = 2018,
  abstract     = {As the frontiers of applied statistics progress
                  through increasingly complex experiments we must
                  exploit increasingly sophisticated inferential
                  models to analyze the observations we make. In order
                  to avoid misleading or outright erroneous inferences
                  we then have to be increasingly diligent in
                  scrutinizing the consequences of those modeling
                  assumptions. Fortunately model-based methods of
                  statistical inference naturally define procedures
                  for quantifying the scope of inferential outcomes
                  and calibrating corresponding decision making
                  processes. In this paper I review the construction
                  and implementation of the particular procedures that
                  arise within frequentist and Bayesian
                  methodologies.},
  archiveprefix= {arXiv},
  eprint       = {1803.08393},
  eprinttype   = {arxiv},
  file         = {/Volumes/GoogleDrive/My Drive/bibliography/Journal
                  Article/Betancourt2018 - Calibrating Model-Based
                  Inferences and Decisions.pdf},
  keywords     = {Statistics - Methodology}
}

@article{Talts2020,
  author       = {Talts, Sean and Betancourt, Michael and Simpson,
                  Daniel and Vehtari, Aki and Gelman, Andrew},
  title        = {Validating {{Bayesian Inference Algorithms}} With
                  {{Simulation}}-{{Based Calibration}}},
  journal      = {arXiv:1804.06788},
  year         = 2020,
  abstract     = {Verifying the correctness of Bayesian computation is
                  challenging. This is especially true for complex
                  models that are common in practice, as these require
                  sophisticated model implementations and
                  algorithms. In this paper we introduce
                  simulation-based calibration (SBC), a general
                  procedure for validating inferences from Bayesian
                  algorithms capable of generating posterior
                  samples. This procedure not only identifies
                  inaccurate computation and inconsistencies in model
                  implementations but also provides graphical
                  summaries that can indicate the nature of the
                  problems that arise. We argue that SBC is a critical
                  part of a robust Bayesian workflow, as well as being
                  a useful tool for those developing computational
                  algorithms and statistical software.},
  archiveprefix= {arXiv},
  eprint       = {1804.06788},
  eprinttype   = {arxiv},
  file         = {/Volumes/GoogleDrive/My Drive/bibliography/Journal
                  Article/Talts2020 - Validating Bayesian Inference
                  Algorithms with Simulation-Based
                  Calibration.pdf;/Volumes/GoogleDrive/My
                  Drive/bibliography/Journal Article/Talts2020 -
                  Validating Bayesian Inference Algorithms with
                  Simulation-Based Calibration2.pdf},
  keywords     = {Statistics - Methodology},
}

@book{Bishop2006,
  author       = {Bishop, Christopher M.},
  title        = {Pattern Recognition and Machine Learning},
  year         = 2006,
  publisher    = {{Springer}},
  address      = {{New York}},
  file         = {/Volumes/GoogleDrive/My
                  Drive/bibliography/Book/Bishop2006 - Pattern
                  recognition and machine learning.pdf},
  isbn         = {978-0-387-31073-2},
  keywords     = {Machine learning,Pattern perception},
  langid       = {english},
  lccn         = {Q327 .B52 2006},
  series       = {Information Science and Statistics},
}

@article{Ruiz2020,
  author       = {Ruiz, Francisco J. R. and Athey, Susan and Blei,
                  David M.},
  title        = {{{SHOPPER}}: a Probabilistic Model of Consumer
                  Choice With Substitutes and Complements},
  journal      = {The Annals of Applied Statistics},
  volume       = 14,
  number       = 1,
  year         = 2020,
  doi          = {10.1214/19-AOAS1265},
  file         = {/Volumes/GoogleDrive/My Drive/bibliography/Journal
                  Article/Ruiz2020 - SHOPPER.pdf},
  issn         = {1932-6157},
  langid       = {english},
  month        = {mar},
  shorttitle   = {{{SHOPPER}}},
}

@article{Blei2017,
  author       = {Blei, David M and Kucukelbir, Alp and McAuliffe, Jon
                  D},
  title        = {Variational Inference: a Review for Statisticians},
  journal      = {Journal of the American Statistical Association},
  year         = 2017,
}

@article{Blei2003,
  author       = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael
                  I.},
  title        = {Latent {{Dirichlet Allocation}}},
  journal      = {Journal of Machine Learning Research},
  volume       = 3,
  number       = {Jan},
  pages        = {993--1022},
  year         = 2003,
  abstract     = {We describe latent Dirichlet allocation (LDA), a
                  generative probabilistic model for collections of
                  discrete data such as text corpora. LDA is a
                  three-level hierarchical Bayesian model, in which
                  each item of a collection is modeled as a finite
                  mixture over an underlying set of topics. Each topic
                  is, in turn, modeled as an infinite mixture over an
                  underlying set of topic probabilities. In the
                  context of text modeling, the topic probabilities
                  provide an explicit representation of a document. We
                  present efficient approximate inference techniques
                  based on variational methods and an EM algorithm for
                  empirical Bayes parameter estimation. We report
                  results in document modeling, text classification,
                  and collaborative filtering, comparing to a mixture
                  of unigrams model and the probabilistic LSI model.},
  file         = {/Volumes/GoogleDrive/My Drive/bibliography/Journal
                  Article/Blei2003 - Latent Dirichlet Allocation.pdf},
  issn         = {ISSN 1533-7928},
}

@article{Kucukelbir2016,
  author       = {Kucukelbir, Alp and Tran, Dustin and Ranganath,
                  Rajesh and Gelman, Andrew and Blei, David M.},
  title        = {Automatic {{Differentiation Variational Inference}}},
  journal      = {arXiv:1603.00788 [cs, stat]},
  year         = 2016,
  abstract     = {Probabilistic modeling is iterative. A scientist
                  posits a simple model, fits it to her data, refines
                  it according to her analysis, and repeats. However,
                  fitting complex models to large data is a bottleneck
                  in this process. Deriving algorithms for new models
                  can be both mathematically and computationally
                  challenging, which makes it difficult to efficiently
                  cycle through the steps. To this end, we develop
                  automatic differentiation variational inference
                  (ADVI). Using our method, the scientist only
                  provides a probabilistic model and a dataset,
                  nothing else. ADVI automatically derives an
                  efficient variational inference algorithm, freeing
                  the scientist to refine and explore many
                  models. ADVI supports a broad class of
                  models\textemdash no conjugacy assumptions are
                  required. We study ADVI across ten different models
                  and apply it to a dataset with millions of
                  observations. ADVI is integrated into Stan, a
                  probabilistic programming system; it is available
                  for immediate use.},
  archiveprefix= {arXiv},
  eprint       = {1603.00788},
  eprinttype   = {arxiv},
  file         = {/Volumes/GoogleDrive/My Drive/bibliography/Journal
                  Article/Kucukelbir2016 - Automatic Differentiation
                  Variational Inference.pdf},
  keywords     = {Computer Science - Artificial Intelligence,Computer
                  Science - Machine Learning,Statistics -
                  Computation,Statistics - Machine Learning},
  langid       = {english},
  month        = {mar},
  primaryclass = {cs, stat},
}

@article{Simpson2017,
  author       = {Simpson, Daniel and {avard Rue}, H{\textbackslash}a
                  and Riebler, Andrea and Martins, Thiago G and
                  S{\o}rbye, Sigrunn H and others},
  title        = {Penalising Model Component Complexity: a Principled,
                  Practical Approach To Constructing Priors},
  journal      = {Statistical science},
  volume       = 32,
  number       = 1,
  pages        = {1--28},
  year         = 2017,
}

@article{Gelman2020,
  author       = {Gelman, Andrew and Vehtari, Aki and Simpson, Daniel
                  and Margossian, Charles C. and Carpenter, Bob and
                  Yao, Yuling and Kennedy, Lauren and Gabry, Jonah and
                  B{\"u}rkner, Paul-Christian and Modr{\'a}k, Martin},
  title        = {Bayesian {{Workflow}}},
  journal      = {arXiv:2011.01808 [stat]},
  year         = 2020,
  abstract     = {The Bayesian approach to data analysis provides a
                  powerful way to handle uncertainty in all
                  observations, model parameters, and model structure
                  using probability theory. Probabilistic programming
                  languages make it easier to specify and fit Bayesian
                  models, but this still leaves us with many options
                  regarding constructing, evaluating, and using these
                  models, along with many remaining challenges in
                  computation. Using Bayesian inference to solve
                  real-world problems requires not only statistical
                  skills, subject matter knowledge, and programming,
                  but also awareness of the decisions made in the
                  process of data analysis. All of these aspects can
                  be understood as part of a tangled workflow of
                  applied Bayesian statistics. Beyond inference, the
                  workflow also includes iterative model building,
                  model checking, validation and troubleshooting of
                  computational problems, model understanding, and
                  model comparison. We review all these aspects of
                  workflow in the context of several examples, keeping
                  in mind that in practice we will be fitting many
                  models for any given problem, even if only a subset
                  of them will ultimately be relevant for our
                  conclusions.},
  archiveprefix= {arXiv},
  eprint       = {2011.01808},
  eprinttype   = {arxiv},
  file         = {/Volumes/GoogleDrive/My Drive/bibliography/Journal
                  Article/Gelman2020 - Bayesian Workflow.pdf},
  keywords     = {Statistics - Methodology},
  langid       = {english},
  month        = {nov},
  primaryclass = {stat},
}

@article{Morris2020,
  author       = {Morris, GE and Gelman, Andrew and Heidemanns,
                  Merlin},
  title        = {How the Economist Presidential Forecast Works},
  journal      = {Economist},
  volume       = 5,
  year         = 2020,
  howpublished =
                  {\url{https://projects.economist.com/us-2020-forecast/president/how-this-works}},
  notes        =
                  {\url{https://github.com/TheEconomist/us-potus-model}},
}

@article{Vehtari2021,
  author       = {Vehtari, Aki and Gelman, Andrew and Simpson, Daniel
                  and Carpenter, Bob and B{\"u}rkner, Paul-Christian},
  title        = {Rank-{{Normalization}}, {{Folding}}, and
                  {{Localization}}: an {{Improved R\textasciicircum}}
                  for {{Assessing Convergence}} of {{MCMC}} (with
                  {{Discussion}})},
  journal      = {Bayesian Analysis},
  volume       = 16,
  number       = 2,
  year         = 2021,
  doi          = {10.1214/20-BA1221},
  file         = {/Volumes/GoogleDrive/My Drive/bibliography/Journal
                  Article/Vehtari2021 - Rank-Normalization, Folding,
                  and Localization.pdf},
  issn         = {1936-0975},
  langid       = {english},
  month        = {jun},
  shorttitle   = {Rank-{{Normalization}}, {{Folding}}, and
                  {{Localization}}},
}

@article{Lambert2020,
  author       = {Lambert, Ben and Vehtari, Aki},
  title        = {\${{R}}\^*\$: a Robust {{MCMC}} Convergence
                  Diagnostic With Uncertainty Using Decision Tree
                  Classifiers},
  journal      = {arXiv:2003.07900 [stat]},
  year         = 2020,
  abstract     = {Markov chain Monte Carlo (MCMC) has transformed
                  Bayesian model inference over the past three
                  decades: mainly because of this, Bayesian inference
                  is now a workhorse of applied scientists. Under
                  general conditions, MCMC sampling converges
                  asymptotically to the posterior distribution, but
                  this provides no guarantees about its performance in
                  finite time. The predominant method for monitoring
                  convergence is to run multiple chains and monitor
                  individual chains' characteristics and compare these
                  to the population as a whole: if within-chain and
                  between-chain summaries are comparable, then this is
                  taken to indicate that the chains have converged to
                  a common stationary distribution. Here, we introduce
                  a new method for diagnosing convergence based on how
                  well a machine learning classifier model can
                  successfully discriminate the individual chains. We
                  call this convergence measure \$R\^*\$. In contrast
                  to the predominant \$\textbackslash widehat\{R\}\$,
                  \$R\^*\$ is a single statistic across all parameters
                  that indicates lack of mixing, although individual
                  variables' importance for this metric can also be
                  determined. Additionally, \$R\^*\$ is not based on
                  any single characteristic of the sampling
                  distribution; instead it uses all the information in
                  the chain, including that given by the joint
                  sampling distribution, which is currently largely
                  overlooked by existing approaches. We recommend
                  calculating \$R\^*\$ using two different machine
                  learning classifiers - gradient-boosted regression
                  trees and random forests - which each work well in
                  models of different dimensions. Because each of
                  these methods outputs a classification probability,
                  as a byproduct, we obtain uncertainty in
                  \$R\^*\$. The method is straightforward to implement
                  and could be a complementary additional check on
                  MCMC convergence for applied analyses.},
  archiveprefix= {arXiv},
  eprint       = {2003.07900},
  eprinttype   = {arxiv},
  file         = {/Volumes/GoogleDrive/My Drive/bibliography/Journal
                  Article/Lambert2020 -
                  $R^$.pdf;/Users/agarbuno/Zotero/storage/K29XD8ZJ/2003.html},
  keywords     = {Statistics - Applications,Statistics - Methodology},
  month        = {nov},
  primaryclass = {stat},
  shorttitle   = {\${{R}}\^*\$},
}

@article{Yao2018,
  author       = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and
                  Gelman, Andrew},
  title        = {Yes, But {{Did It Work}}?: Evaluating {{Variational
                  Inference}}},
  journal      = {arXiv:1802.02538 [stat]},
  year         = 2018,
  abstract     = {While it's always possible to compute a variational
                  approximation to a posterior distribution, it can be
                  difficult to discover problems with this
                  approximation. We propose two diagnostic algorithms
                  to alleviate this problem. The Paretosmoothed
                  importance sampling (PSIS) diagnostic gives a
                  goodness of fit measurement for joint distributions,
                  while simultaneously improving the error in the
                  estimate. The variational simulationbased
                  calibration (VSBC) assesses the average performance
                  of point estimates.},
  archiveprefix= {arXiv},
  eprint       = {1802.02538},
  eprinttype   = {arxiv},
  file         = {/Volumes/GoogleDrive/My Drive/bibliography/Journal
                  Article/Yao2018 - Yes, but Did It Work.pdf},
  keywords     = {Statistics - Computation,Statistics - Machine
                  Learning},
  langid       = {english},
  month        = {jul},
  primaryclass = {stat},
  shorttitle   = {Yes, but {{Did It Work}}?},
}

@article{Yao2018,
  author       = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and
                  Gelman, Andrew},
  title        = {Using {{Stacking}} To {{Average Bayesian Predictive
                  Distributions}} (with {{Discussion}})},
  journal      = {Bayesian Analysis},
  volume       = 13,
  number       = 3,
  year         = 2018,
  doi          = {10.1214/17-BA1091},
  abstract     = {Bayesian model averaging is flawed in the M-open
                  setting in which the true data-generating process is
                  not one of the candidate models being fit. We take
                  the idea of stacking from the point estimation
                  literature and generalize to the combination of
                  predictive distributions. We extend the utility
                  function to any proper scoring rule and use Pareto
                  smoothed importance sampling to efficiently compute
                  the required leave-one-out posterior
                  distributions. We compare stacking of predictive
                  distributions to several alternatives: stacking of
                  means, Bayesian model averaging (BMA), Pseudo-BMA,
                  and a variant of Pseudo-BMA that is stabilized using
                  the Bayesian bootstrap. Based on simulations and
                  real-data applications, we recommend stacking of
                  predictive distributions, with
                  bootstrapped-Pseudo-BMA as an approximate
                  alternative when computation cost is an issue.},
  file         = {/Volumes/GoogleDrive/My Drive/bibliography/Journal
                  Article/Yao2018 - Using Stacking to Average Bayesian
                  Predictive Distributions (with Discussion).pdf},
  issn         = {1936-0975},
  langid       = {english},
  month        = {sep},
}

@article{Sivula2020,
  author       = {Sivula, Tuomas and Magnusson, M{\aa}ns and Vehtari,
                  Aki},
  title        = {Uncertainty in {{Bayesian Leave-One-Out
                  Cross-Validation Based Model Comparison}}},
  journal      = {arXiv:2008.10296 [stat]},
  year         = 2020,
  abstract     = {Leave-one-out cross-validation (LOO-CV) is a popular
                  method for comparing Bayesian models based on their
                  estimated predictive performance on new, unseen,
                  data. Estimating the uncertainty of the resulting
                  LOO-CV estimate is a complex task and it is known
                  that the commonly used standard error estimate is
                  often too small. We analyse the frequency properties
                  of the LOO-CV estimator and study the uncertainty
                  related to it. We provide new results of the
                  properties of the uncertainty both theoretically and
                  empirically and discuss the challenges of estimating
                  it. We show that problematic cases include:
                  comparing models with similar predictions,
                  misspecified models, and small data. In these cases,
                  there is a weak connection in the skewness of the
                  sampling distribution and the distribution of the
                  error of the LOO-CV estimator. We show that it is
                  possible that the problematic skewness of the error
                  distribution, which occurs when the models make
                  similar predictions, does not fade away when the
                  data size grows to infinity in certain situations.},
  archiveprefix= {arXiv},
  eprint       = {2008.10296},
  eprinttype   = {arxiv},
  file         = {/Volumes/GoogleDrive/My Drive/bibliography/Journal
                  Article/Sivula2020 - Uncertainty in Bayesian
                  Leave-One-Out Cross-Validation Based Model
                  Comparison.pdf;/Users/agarbuno/Zotero/storage/3C5CHTVP/2008.html},
  keywords     = {Statistics - Methodology},
  month        = {oct},
  primaryclass = {stat},
}

@article{Mikkola2021,
  author       = {Mikkola, Petrus and Martin, Osvaldo A. and
                  Chandramouli, Suyog and Hartmann, Marcelo and Pla,
                  Oriol Abril and Thomas, Owen and Pesonen, Henri and
                  Corander, Jukka and Vehtari, Aki and Kaski, Samuel
                  and B{\"u}rkner, Paul-Christian and Klami, Arto},
  title        = {Prior Knowledge Elicitation: {{The}} Past, Present,
                  and Future},
  journal      = {arXiv:2112.01380 [stat]},
  year         = 2021,
  abstract     = {Specification of the prior distribution for a
                  Bayesian model is a central part of the Bayesian
                  workflow for data analysis, but it is often
                  difficult even for statistical experts. Prior
                  elicitation transforms domain knowledge of various
                  kinds into well-defined prior distributions, and
                  offers a solution to the prior specification
                  problem, in principle. In practice, however, we are
                  still fairly far from having usable prior
                  elicitation tools that could significantly influence
                  the way we build probabilistic models in academia
                  and industry. We lack elicitation methods that
                  integrate well into the Bayesian workflow and
                  perform elicitation efficiently in terms of costs of
                  time and effort. We even lack a comprehensive
                  theoretical framework for understanding different
                  facets of the prior elicitation problem. Why are we
                  not widely using prior elicitation? We analyze the
                  state of the art by identifying a range of key
                  aspects of prior knowledge elicitation, from
                  properties of the modelling task and the nature of
                  the priors to the form of interaction with the
                  expert. The existing prior elicitation literature is
                  reviewed and categorized in these terms. This allows
                  recognizing under-studied directions in prior
                  elicitation research, finally leading to a proposal
                  of several new avenues to improve prior elicitation
                  methodology.},
  archiveprefix= {arXiv},
  eprint       = {2112.01380},
  eprinttype   = {arxiv},
  file         = {/Volumes/GoogleDrive/My Drive/bibliography/Journal
                  Article/Mikkola2021 - Prior knowledge
                  elicitation2.pdf;/Users/agarbuno/Zotero/storage/9DFNSFKT/2112.html},
  keywords     = {Statistics - Methodology},
  month        = {dec},
  primaryclass = {stat},
  shorttitle   = {Prior Knowledge Elicitation},
}

